// import { NextRequest, NextResponse } from "next/server";
// import { connectToDatabase } from "@/lib/mongodb";
// import GameModel from "@/models/Game";
// import { currentUser } from "@clerk/nextjs/server";
// import { prisma } from "@/lib/prisma";
// import { resolveModelsForChat, incrementApiUsage, IncrementApiUsageParams } from "@/lib/modelSelection";
// import { callOpenAIChat, performAiReviewCycle, AiReviewCycleRawOutputs } from "@/lib/aiService";
// import { ChatCompletionMessageParam, ChatCompletionSystemMessageParam } from "openai/resources/chat/completions";

// const FALLBACK_COLLECT_CODER_SYSTEM_PROMPT_TEMPLATE = `
// You are an AI assistant specialized in creating custom surveys for the RandomPlayables platform.
// You help users design effective surveys, questionnaires, and data collection tools that can
// optionally incorporate interactive games.

// Available games that can be integrated into surveys:
// %%AVAILABLE_GAMES_LIST%%

// When helping design surveys:
// 1. Ask clarifying questions about the user's research goals and target audience
// 2. Suggest appropriate question types (multiple choice, Likert scale, open-ended, etc.)
// 3. Help write clear, unbiased questions
// 4. Recommend game integration where appropriate for engagement or data collection
// 5. Advise on survey flow and organization

// When designing a survey with game integration:
// 1. Explain how the game data will complement traditional survey questions
// 2. Discuss how to interpret combined qualitative and quantitative results
// 3. Suggest appropriate placement of games within the survey flow

// Return your suggestions in a clear, structured format. If suggesting multiple questions,
// number them and specify the question type for each.
// `;

// const FALLBACK_COLLECT_REVIEWER_SYSTEM_PROMPT = `
// You are an AI expert in survey design and data collection methodologies. Your task is to review a survey draft that was generated by another AI assistant.
// The initial AI was given a user's query and a system prompt to guide its generation.
// Focus your review on:
// 1.  **Clarity and Unambiguity:** Are the questions clear, concise, and easy to understand? Is there any potential for misinterpretation?
// 2.  **Effectiveness:** Do the questions effectively address the likely research goals implied by the user's query and the initial generation?
// 3.  **Question Types:** Are the suggested question types (e.g., multiple choice, Likert scale, open-ended) appropriate for the information being sought?
// 4.  **Game Integration (if applicable):** If a game is integrated or suggested, is the integration meaningful? Does it enhance data collection or engagement appropriately?
// 5.  **Bias:** Are there any leading questions or biases in the phrasing?
// 6.  **Flow and Organization:** Is the survey logically structured?
// 7.  **Completeness:** Are there any obvious omissions based on the initial request?

// Provide constructive feedback. Be specific in your suggestions. If you identify issues, explain why they are problematic and suggest improvements.
// Return only your review.
// `;

// async function fetchActiveGamesList() {
//   await connectToDatabase();
//   const games = await GameModel.find({}, {
//     id: 1, name: 1, description: 1, _id: 0
//   }).limit(10).lean();
//   return games;
// }

// function getMonthlyLimitForTier(tier?: string | null): number {
//     switch (tier) {
//       case "premium":
//         return 500;
//       case "premium_plus":
//         return 1500;
//       default:
//         return 100; 
//     }
//   }

// export async function POST(request: NextRequest) {
//   try {
//     const clerkUser = await currentUser();
//     if (!clerkUser || !clerkUser.id) {
//       return NextResponse.json({ error: "Unauthorized" }, { status: 401 });
//     }

//     const { 
//         message: userQuery, 
//         chatHistory, 
//         coderSystemPrompt, // Renamed from customSystemPrompt for clarity
//         reviewerSystemPrompt, // New prompt for reviewer
//         useCodeReview, 
//         selectedCoderModelId, 
//         selectedReviewerModelId 
//     } = await request.json();

//     const profile = await prisma.profile.findUnique({
//         where: { userId: clerkUser.id },
//         select: { subscriptionActive: true, subscriptionTier: true },
//     });
//     const isSubscribed = profile?.subscriptionActive || false;

//     const games = await fetchActiveGamesList();
//     const gamesListString = JSON.stringify(games, null, 2);

//     let coderSystemPromptToUse: string;
//     if (coderSystemPrompt && coderSystemPrompt.trim() !== "") {
//       coderSystemPromptToUse = coderSystemPrompt;
//       if (coderSystemPromptToUse.includes("%%AVAILABLE_GAMES_LIST%%")) {
//         coderSystemPromptToUse = coderSystemPromptToUse.replace("%%AVAILABLE_GAMES_LIST%%", gamesListString);
//       }
//     } else {
//       coderSystemPromptToUse = FALLBACK_COLLECT_CODER_SYSTEM_PROMPT_TEMPLATE.replace("%%AVAILABLE_GAMES_LIST%%", gamesListString);
//     }

//     let reviewerSystemPromptToUse: string | null = null;
//     if (useCodeReview) {
//         let prompt: string;
//         if (reviewerSystemPrompt && reviewerSystemPrompt.trim() !== "") {
//             prompt = reviewerSystemPrompt;
//         } else {
//             prompt = FALLBACK_COLLECT_REVIEWER_SYSTEM_PROMPT.replace("%%AVAILABLE_GAMES_LIST%%", gamesListString);
//         }
        
//         if (prompt.includes("%%AVAILABLE_GAMES_LIST%%")) {
//             prompt = prompt.replace("%%AVAILABLE_GAMES_LIST%%", gamesListString);
//         }
        
//         reviewerSystemPromptToUse = prompt;
//     }
    
//     let finalApiResponse: { message: string; remainingRequests?: number; error?: string; limitReached?: boolean };

//     const initialUserMessages: ChatCompletionMessageParam[] = [
//         ...(chatHistory.map((msg: any) => ({ role: msg.role, content: msg.content })) as ChatCompletionMessageParam[]),
//         { role: "user", content: userQuery }
//     ];
    
//     const coderSystemMessage: ChatCompletionSystemMessageParam = { role: "system", content: coderSystemPromptToUse };
//     const reviewerSystemMessage: ChatCompletionSystemMessageParam | null = reviewerSystemPromptToUse ? { role: "system", content: reviewerSystemPromptToUse } : null;


//     const modelResolution = await resolveModelsForChat(
//         clerkUser.id, 
//         isSubscribed, 
//         useCodeReview, 
//         selectedCoderModelId, 
//         selectedReviewerModelId
//     );

//     if (!modelResolution.canUseApi || modelResolution.limitReached) {
//       return NextResponse.json({
//         error: modelResolution.error || "Monthly API request limit reached.",
//         limitReached: true
//       }, { status: modelResolution.limitReached ? 403 : 400 });
//     }
//      if (modelResolution.error) {
//         return NextResponse.json({ error: modelResolution.error }, { status: 400 });
//     }

//     if (useCodeReview) {
//       if (!modelResolution.chatbot1Model || !modelResolution.chatbot2Model) {
//         console.error("Collect API: Code review models not resolved properly for user", clerkUser.id);
//         return NextResponse.json({ error: "Failed to resolve models for code review." }, { status: 500 });
//       }
//       const chatbot1ModelToUse = modelResolution.chatbot1Model;
//       const chatbot2ModelToUse = modelResolution.chatbot2Model;

//       // The user message to the reviewer includes the coder's system prompt for context
//       const createReviewerPrompt = (initialSurveyDesign: string | null): string => `
// You are reviewing a survey draft. Below is the original user request, the system prompt given to the AI that drafted the survey, and the draft itself.
// Your task is to provide a critical review based on the system prompt you (the reviewer) received separately.

// Original User Prompt to Initial AI (Chatbot1):
// ---
// ${userQuery}
// ---
// System Prompt used for Initial AI (Chatbot1):
// ---
// ${coderSystemPromptToUse}
// ---
// Survey Design generated by Initial AI (Chatbot1):
// ---
// ${initialSurveyDesign || "Chatbot1 did not provide an initial survey design."}
// ---
// Your review of the survey design (focus on clarity, effectiveness, question types, game integration, bias, flow, and completeness based on your reviewer system prompt):`;

//       // The user message to the coder for revision includes its original system prompt for context
//       const createRevisionPrompt = (initialSurveyDesign: string | null, reviewFromChatbot2: string | null): string => `
// You are the AI assistant that generated an initial survey design. Your previous work was reviewed by another AI.
// Based on the review, please revise your initial survey design.

// Original User Prompt:
// ---
// ${userQuery}
// ---
// Original System Prompt You Followed:
// ---
// ${coderSystemPromptToUse}
// ---
// Your Initial Survey Design:
// ---
// ${initialSurveyDesign || "No initial survey design was provided."}
// ---
// Review of Your Design (from Chatbot2):
// ---
// ${reviewFromChatbot2 || "No review feedback provided."}
// ---
// Your Revised Survey Design (incorporate the feedback and adhere to your original system prompt):`;

//       const reviewCycleOutputs: AiReviewCycleRawOutputs = await performAiReviewCycle(
//         chatbot1ModelToUse, 
//         coderSystemMessage, // System prompt for Coder (Chatbot1)
//         initialUserMessages, 
//         chatbot2ModelToUse,
//         reviewerSystemMessage, // System prompt for Reviewer (Chatbot2)
//         createReviewerPrompt, 
//         createRevisionPrompt
//       );
//       finalApiResponse = { 
//         message: reviewCycleOutputs.chatbot1RevisionResponse.content || reviewCycleOutputs.chatbot1InitialResponse.content || "Could not generate a revised response.",
//       };
//     } else {
//       if (!modelResolution.chatbot1Model) {
//         console.error("Collect API: Primary model not resolved properly for user", clerkUser.id);
//         return NextResponse.json({ error: "Failed to resolve model." }, { status: 500 });
//       }
//       const modelToUse = modelResolution.chatbot1Model;
//       const messagesToAI: ChatCompletionMessageParam[] = [coderSystemMessage, ...initialUserMessages];
//       const response = await callOpenAIChat(modelToUse, messagesToAI);
//       finalApiResponse = { 
//         message: response.choices[0].message.content || "Could not generate a response.",
//       };
//     }
    
//     const incrementParams: IncrementApiUsageParams = {
//         userId: clerkUser.id,
//         isSubscribed: isSubscribed,
//         useCodeReview: useCodeReview,
//         coderModelId: modelResolution.chatbot1Model, 
//         reviewerModelId: useCodeReview ? modelResolution.chatbot2Model : null
//     };
//     await incrementApiUsage(incrementParams);
    
//     const usageData = await prisma.apiUsage.findUnique({ where: { userId: clerkUser.id } });
//     if (usageData) {
//         finalApiResponse.remainingRequests = Math.max(0, (usageData.monthlyLimit) - (usageData.usageCount));
//     } else {
//         const limitForUser = getMonthlyLimitForTier(profile?.subscriptionTier);
//         finalApiResponse.remainingRequests = limitForUser;
//     }
    
//     return NextResponse.json(finalApiResponse);

//   } catch (error: any) {
//     console.error("Error in Collect chat:", error);
//     let errorDetails = error.message;
//     if (error.response && error.response.data && error.response.data.error) {
//         errorDetails = error.response.data.error.message || error.message;
//     }
//     return NextResponse.json(
//       { error: "Failed to generate survey suggestion", details: errorDetails, stack: error.stack },
//       { status: 500 }
//     );
//   }
// }




import { NextRequest, NextResponse } from "next/server";
import { connectToDatabase } from "@/lib/mongodb";
import GameModel from "@/models/Game";
import { currentUser } from "@clerk/nextjs/server";
import { prisma } from "@/lib/prisma";
import { resolveModelsForChat, incrementApiUsage, IncrementApiUsageParams } from "@/lib/modelSelection";
import { callOpenAIChat, performAiReviewCycle, AiReviewCycleRawOutputs } from "@/lib/aiService";
import { ChatCompletionMessageParam, ChatCompletionSystemMessageParam } from "openai/resources/chat/completions";

const FALLBACK_COLLECT_CODER_SYSTEM_PROMPT_TEMPLATE = `
You are an AI assistant specialized in creating custom surveys for the RandomPlayables platform.
You help users design effective surveys, questionnaires, and data collection tools that can
optionally incorporate interactive games.

When a user asks to integrate a game, you MUST use the exact 'gameId' from the list below and format the question as a numbered list item, like this: "1. Game Integration: your-game-id-here".

Available games that can be integrated into surveys:
%%AVAILABLE_GAMES_LIST%%

When helping design surveys:
1. Ask clarifying questions about the user's research goals and target audience
2. Suggest appropriate question types (multiple choice, Likert scale, open-ended, etc.)
3. Help write clear, unbiased questions
4. Recommend game integration where appropriate for engagement or data collection
5. Advise on survey flow and organization

When designing a survey with game integration:
1. Explain how the game data will complement traditional survey questions
2. Discuss how to interpret combined qualitative and quantitative results
3. Suggest appropriate placement of games within the survey flow

Return your suggestions in a clear, structured format. If suggesting multiple questions,
number them and specify the question type for each. For game integrations, use the required format: "X. Game Integration: gameId".
`;

const FALLBACK_COLLECT_REVIEWER_SYSTEM_PROMPT = `
You are an AI expert in survey design and data collection methodologies. Your task is to review a survey draft that was generated by another AI assistant.
The initial AI was given a user's query and a system prompt to guide its generation.
Focus your review on:
1.  **Clarity and Unambiguity:** Are the questions clear, concise, and easy to understand? Is there any potential for misinterpretation?
2.  **Effectiveness:** Do the questions effectively address the likely research goals implied by the user's query and the initial generation?
3.  **Question Types:** Are the suggested question types (e.g., multiple choice, Likert scale, open-ended) appropriate for the information being sought?
4.  **Game Integration (if applicable):** If a game is integrated or suggested, is the integration meaningful? Does it enhance data collection or engagement appropriately? Does it follow the specified format "X. Game Integration: gameId"?
5.  **Bias:** Are there any leading questions or biases in the phrasing?
6.  **Flow and Organization:** Is the survey logically structured?
7.  **Completeness:** Are there any obvious omissions based on the initial request?

Provide constructive feedback. Be specific in your suggestions. If you identify issues, explain why they are problematic and suggest improvements.
Return only your review.
`;

async function fetchActiveGamesList() {
  await connectToDatabase();
  const games = await GameModel.find({}, {
    gameId: 1, name: 1, description: 1, _id: 0
  }).limit(20).lean();
  return games;
}

function getMonthlyLimitForTier(tier?: string | null): number {
    switch (tier) {
      case "premium":
        return 500;
      case "premium_plus":
        return 1500;
      default:
        return 100; 
    }
  }

export async function POST(request: NextRequest) {
  try {
    const clerkUser = await currentUser();
    if (!clerkUser || !clerkUser.id) {
      return NextResponse.json({ error: "Unauthorized" }, { status: 401 });
    }

    const { 
        message: userQuery, 
        chatHistory, 
        coderSystemPrompt, // Renamed from customSystemPrompt for clarity
        reviewerSystemPrompt, // New prompt for reviewer
        useCodeReview, 
        selectedCoderModelId, 
        selectedReviewerModelId 
    } = await request.json();

    const profile = await prisma.profile.findUnique({
        where: { userId: clerkUser.id },
        select: { subscriptionActive: true, subscriptionTier: true },
    });
    const isSubscribed = profile?.subscriptionActive || false;

    const games = await fetchActiveGamesList();
    const gamesListString = JSON.stringify(games, null, 2);

    let coderSystemPromptToUse: string;
    if (coderSystemPrompt && coderSystemPrompt.trim() !== "") {
      coderSystemPromptToUse = coderSystemPrompt;
      if (coderSystemPromptToUse.includes("%%AVAILABLE_GAMES_LIST%%")) {
        coderSystemPromptToUse = coderSystemPromptToUse.replace("%%AVAILABLE_GAMES_LIST%%", gamesListString);
      }
    } else {
      coderSystemPromptToUse = FALLBACK_COLLECT_CODER_SYSTEM_PROMPT_TEMPLATE.replace("%%AVAILABLE_GAMES_LIST%%", gamesListString);
    }

    let reviewerSystemPromptToUse: string | null = null;
    if (useCodeReview) {
        let prompt: string;
        if (reviewerSystemPrompt && reviewerSystemPrompt.trim() !== "") {
            prompt = reviewerSystemPrompt;
        } else {
            prompt = FALLBACK_COLLECT_REVIEWER_SYSTEM_PROMPT.replace("%%AVAILABLE_GAMES_LIST%%", gamesListString);
        }
        
        if (prompt.includes("%%AVAILABLE_GAMES_LIST%%")) {
            prompt = prompt.replace("%%AVAILABLE_GAMES_LIST%%", gamesListString);
        }
        
        reviewerSystemPromptToUse = prompt;
    }
    
    let finalApiResponse: { message: string; remainingRequests?: number; error?: string; limitReached?: boolean };

    const initialUserMessages: ChatCompletionMessageParam[] = [
        ...(chatHistory.map((msg: any) => ({ role: msg.role, content: msg.content })) as ChatCompletionMessageParam[]),
        { role: "user", content: userQuery }
    ];
    
    const coderSystemMessage: ChatCompletionSystemMessageParam = { role: "system", content: coderSystemPromptToUse };
    const reviewerSystemMessage: ChatCompletionSystemMessageParam | null = reviewerSystemPromptToUse ? { role: "system", content: reviewerSystemPromptToUse } : null;


    const modelResolution = await resolveModelsForChat(
        clerkUser.id, 
        isSubscribed, 
        useCodeReview, 
        selectedCoderModelId, 
        selectedReviewerModelId
    );

    if (!modelResolution.canUseApi || modelResolution.limitReached) {
      return NextResponse.json({
        error: modelResolution.error || "Monthly API request limit reached.",
        limitReached: true
      }, { status: modelResolution.limitReached ? 403 : 400 });
    }
     if (modelResolution.error) {
        return NextResponse.json({ error: modelResolution.error }, { status: 400 });
    }

    if (useCodeReview) {
      if (!modelResolution.chatbot1Model || !modelResolution.chatbot2Model) {
        console.error("Collect API: Code review models not resolved properly for user", clerkUser.id);
        return NextResponse.json({ error: "Failed to resolve models for code review." }, { status: 500 });
      }
      const chatbot1ModelToUse = modelResolution.chatbot1Model;
      const chatbot2ModelToUse = modelResolution.chatbot2Model;

      // The user message to the reviewer includes the coder's system prompt for context
      const createReviewerPrompt = (initialSurveyDesign: string | null): string => `
You are reviewing a survey draft. Below is the original user request, the system prompt given to the AI that drafted the survey, and the draft itself.
Your task is to provide a critical review based on the system prompt you (the reviewer) received separately.

Original User Prompt to Initial AI (Chatbot1):
---
${userQuery}
---
System Prompt used for Initial AI (Chatbot1):
---
${coderSystemPromptToUse}
---
Survey Design generated by Initial AI (Chatbot1):
---
${initialSurveyDesign || "Chatbot1 did not provide an initial survey design."}
---
Your review of the survey design (focus on clarity, effectiveness, question types, game integration, bias, flow, and completeness based on your reviewer system prompt):`;

      // The user message to the coder for revision includes its original system prompt for context
      const createRevisionPrompt = (initialSurveyDesign: string | null, reviewFromChatbot2: string | null): string => `
You are the AI assistant that generated an initial survey design. Your previous work was reviewed by another AI.
Based on the review, please revise your initial survey design.

Original User Prompt:
---
${userQuery}
---
Original System Prompt You Followed:
---
${coderSystemPromptToUse}
---
Your Initial Survey Design:
---
${initialSurveyDesign || "No initial survey design was provided."}
---
Review of Your Design (from Chatbot2):
---
${reviewFromChatbot2 || "No review feedback provided."}
---
Your Revised Survey Design (incorporate the feedback and adhere to your original system prompt):`;

      const reviewCycleOutputs: AiReviewCycleRawOutputs = await performAiReviewCycle(
        chatbot1ModelToUse, 
        coderSystemMessage, // System prompt for Coder (Chatbot1)
        initialUserMessages, 
        chatbot2ModelToUse,
        reviewerSystemMessage, // System prompt for Reviewer (Chatbot2)
        createReviewerPrompt, 
        createRevisionPrompt
      );
      finalApiResponse = { 
        message: reviewCycleOutputs.chatbot1RevisionResponse.content || reviewCycleOutputs.chatbot1InitialResponse.content || "Could not generate a revised response.",
      };
    } else {
      if (!modelResolution.chatbot1Model) {
        console.error("Collect API: Primary model not resolved properly for user", clerkUser.id);
        return NextResponse.json({ error: "Failed to resolve model." }, { status: 500 });
      }
      const modelToUse = modelResolution.chatbot1Model;
      const messagesToAI: ChatCompletionMessageParam[] = [coderSystemMessage, ...initialUserMessages];
      const response = await callOpenAIChat(modelToUse, messagesToAI);
      finalApiResponse = { 
        message: response.choices[0].message.content || "Could not generate a response.",
      };
    }
    
    const incrementParams: IncrementApiUsageParams = {
        userId: clerkUser.id,
        isSubscribed: isSubscribed,
        useCodeReview: useCodeReview,
        coderModelId: modelResolution.chatbot1Model, 
        reviewerModelId: useCodeReview ? modelResolution.chatbot2Model : null
    };
    await incrementApiUsage(incrementParams);
    
    const usageData = await prisma.apiUsage.findUnique({ where: { userId: clerkUser.id } });
    if (usageData) {
        finalApiResponse.remainingRequests = Math.max(0, (usageData.monthlyLimit) - (usageData.usageCount));
    } else {
        const limitForUser = getMonthlyLimitForTier(profile?.subscriptionTier);
        finalApiResponse.remainingRequests = limitForUser;
    }
    
    return NextResponse.json(finalApiResponse);

  } catch (error: any) {
    console.error("Error in Collect chat:", error);
    let errorDetails = error.message;
    if (error.response && error.response.data && error.response.data.error) {
        errorDetails = error.response.data.error.message || error.message;
    }
    return NextResponse.json(
      { error: "Failed to generate survey suggestion", details: errorDetails, stack: error.stack },
      { status: 500 }
    );
  }
}